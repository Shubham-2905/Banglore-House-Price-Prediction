{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importing essential libraries\n",
    "import numpy as np\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Loading the dataset\n",
    "df = pd.read_csv('C:/Users/Admin/Desktop/Banglore_House_Data/Bengaluru_House_Data.csv')\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Exploring the dataset\n",
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Exploring the dataset\n",
    "df.groupby('area_type')['area_type'].agg('count')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Exploring the dataset\n",
    "df.groupby('availability')['availability'].agg('count')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Exploring the dataset\n",
    "df.groupby('size')['size'].agg('count')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Removing the columns of society\n",
    "df = df.drop('society', axis='columns')\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Cleaning Process"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Data Cleaning\n",
    "# Checking the null values in the dataset\n",
    "df.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Applying median to the balcony and bath column\n",
    "from math import floor\n",
    "\n",
    "balcony_median = float(floor(df.balcony.median()))\n",
    "bath_median = float(floor(df.bath.median()))\n",
    "\n",
    "df.balcony = df.balcony.fillna(balcony_median)\n",
    "df.bath = df.bath.fillna(bath_median)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Checking the null values in the dataset again\n",
    "df.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dropping the rows with null values because the dataset is huge as compared to null values.\n",
    "df = df.dropna()\n",
    "df.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Converting the size column to bhk\n",
    "df['bhk'] = df['size'].apply(lambda x: int(x.split(' ')[0]))\n",
    "df = df.drop('size', axis='columns')\n",
    "df.groupby('bhk')['bhk'].agg('count')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Exploring the total_sqft column\n",
    "df.total_sqft.unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Since the total_sqft contains range values such as 1133-1384, lets filter out these values\n",
    "def isFloat(x):\n",
    "    try:\n",
    "        float(x)\n",
    "    except:\n",
    "        return False\n",
    "    return True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Displaying all the rows that are not integers\n",
    "df[~df['total_sqft'].apply(isFloat)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Converting the range values to integer values and removing other types of error\n",
    "def convert_sqft_to_num(x):\n",
    "    tokens = x.split('-')\n",
    "    if len(tokens) == 2:\n",
    "        return (float(tokens[0])+float(tokens[1]))/2\n",
    "    try:\n",
    "        return float(x)\n",
    "    except:\n",
    "        return None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "df['new_total_sqft'] = df.total_sqft.apply(convert_sqft_to_num)\n",
    "df = df.drop('total_sqft', axis='columns')\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Removing the rows in new_total_sqft column that hase None values\n",
    "df.isna().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Removing the rows in new_total_sqft column that hase None values\n",
    "df = df.dropna()\n",
    "df.isna().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Feature Engineering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Adding a new column of price_per_sqft\n",
    "df1 = df.copy()\n",
    "\n",
    "# In our dataset the price column is in Lakhs\n",
    "df1['price_per_sqft'] = (df1['price']*100000)/df1['new_total_sqft']\n",
    "df1.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "\n",
    "# Checking unique values of 'location' column\n",
    "locations = list(df['location'].unique())\n",
    "print(len(locations))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# Removing the extra spaces at the end\n",
    "df1.location = df1.location.apply(lambda x: x.strip())\n",
    "\n",
    "# Calulating all the unqiue values in 'location' column\n",
    "location_stats = df1.groupby('location')['location'].agg('count').sort_values(ascending=False)\n",
    "location_stats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# Checking locations with less than 10 values\n",
    "print(len(location_stats[location_stats<=10]), len(df1.location.unique()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df1.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Labelling the locations with less than or equal to 10 occurences to 'other'\n",
    "locations_less_than_10 = location_stats[location_stats<=10]\n",
    "\n",
    "df1.location = df1.location.apply(lambda x: 'other' if x in locations_less_than_10 else x)\n",
    "len(df1.location.unique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Checking the unique values in 'availability column'\n",
    "df1.groupby('availability')['availability'].agg('count').sort_values(ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Labelling the dates into Not Ready\n",
    "dates = df1.groupby('availability')['availability'].agg('count').sort_values(ascending=False)\n",
    "\n",
    "dates_not_ready = dates[dates<10000]\n",
    "df1.availability = df1.availability.apply(lambda x: 'Not Ready' if x in dates_not_ready else x)\n",
    "\n",
    "len(df1.availability.unique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "df1.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Checking the unique values in 'area_type' column\n",
    "df1.groupby('area_type')['area_type'].agg('count').sort_values(ascending=False)\n",
    "\n",
    "# Since the column has only few unique values, we don't perform any operation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Removing Outliers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Removing the rows that have 1 Room for less than 300sqft\n",
    "\n",
    "df2 = df1[~(df1.new_total_sqft/df1.bhk<300)]\n",
    "print(len(df2), len(df1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df2.price_per_sqft.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Since there is a wide range for 'price_per_sqft' column with min = Rs.267/sqft till max = Rs. 127470/sqft, we remove the extreme ends using the SD\n",
    "def remove_pps_outliers(df):\n",
    "    \n",
    "    df_out = pd.DataFrame()\n",
    "    \n",
    "    for key, sub_df in df.groupby('location'):\n",
    "        m = np.mean(sub_df.price_per_sqft)\n",
    "        sd = np.std(sub_df.price_per_sqft)\n",
    "        reduce_df = sub_df[(sub_df.price_per_sqft>(m-sd)) & (sub_df.price_per_sqft<(m+sd))]\n",
    "        df_out = pd.concat([df_out, reduce_df], ignore_index=True)\n",
    "    \n",
    "    return df_out\n",
    "\n",
    "df3 = remove_pps_outliers(df2)\n",
    "print(len(df2), len(df3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Here we observe that 3 BHK cost that same as 2 BHK in 'Hebbal' location hence removing such outliers is necessary\n",
    "def remove_bhk_outliers(df):\n",
    "    exclude_indices = np.array([])\n",
    "    \n",
    "    for location, location_df in df.groupby('location'):\n",
    "        bhk_stats = {}\n",
    "        \n",
    "        for bhk, bhk_df in location_df.groupby('bhk'):\n",
    "            bhk_stats[bhk] = {\n",
    "                'mean': np.mean(bhk_df.price_per_sqft),\n",
    "                'std': np.std(bhk_df.price_per_sqft),\n",
    "                'count': bhk_df.shape[0]\n",
    "            }\n",
    "        \n",
    "        for bhk, bhk_df in location_df.groupby('bhk'):\n",
    "            stats = bhk_stats.get(bhk-1)\n",
    "            if stats and stats['count']>5:\n",
    "                exclude_indices = np.append(exclude_indices, bhk_df[bhk_df.price_per_sqft<(stats['mean'])].index.values)\n",
    "    \n",
    "    return df.drop(exclude_indices, axis='index')\n",
    "\n",
    "df4 = remove_bhk_outliers(df3)\n",
    "print(len(df3), len(df4))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Removing the rows that have 'bath' greater than 'bhk'+2\n",
    "df5 = df4[df4.bath<(df4.bhk+2)]\n",
    "print(len(df4), len(df5))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df5.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model Building"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Removing the unnecessary columns (columns that were added only for removing the outliers)\n",
    "df6 = df5.copy()\n",
    "df6 = df6.drop('price_per_sqft', axis='columns')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df6.location.unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(df6.location.unique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Converting the categorical_value into numerical_values using get_dummies method\n",
    "dummy_cols = pd.get_dummies(df6.location).drop('other', axis='columns')\n",
    "df6 = pd.concat([df6,dummy_cols], axis='columns')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Converting the categorical_value into numerical_values using get_dummies method\n",
    "dummy_cols = pd.get_dummies(df6.availability).drop('Not Ready', axis='columns')\n",
    "df6 = pd.concat([df6,dummy_cols], axis='columns')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Converting the categorical_value into numerical_values using get_dummies method\n",
    "dummy_cols = pd.get_dummies(df6.area_type).drop('Super built-up  Area', axis='columns')\n",
    "df6 = pd.concat([df6,dummy_cols], axis='columns')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "df6.drop(['area_type','availability','location'], axis='columns', inplace=True)\n",
    "df6.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Size of the dataset\n",
    "df6.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Splitting the dataset into features and label\n",
    "X = df6.drop('price', axis='columns')\n",
    "y = df6['price']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Splitting the dataset into train and test set\n",
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.20, random_state=20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LinearRegression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creating Linear Regression Model\n",
    "model = LinearRegression(normalize=True)\n",
    "model.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.score(X_test, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Predicting the values using our trained model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# For finding the appropriate location\n",
    "np.where(X.columns=='2nd Phase Judicial Layout')[0][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# For finding the appropriate area_type\n",
    "np.where(X.columns=='Built-up  Area')[0][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# For finding the appropriate availability\n",
    "np.where(X.columns=='Ready To Move')[0][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creating a fuction to predict values\n",
    "def prediction(location, bhk, bath, balcony, sqft, area_type, availability):\n",
    "    \n",
    "    loc_index, area_index, avail_index = -1,-1,-1\n",
    "        \n",
    "    if location!='other':\n",
    "        loc_index = int(np.where(X.columns==location)[0][0])\n",
    "    \n",
    "    if area_type!='Super built-up  Area':\n",
    "        area_index = np.where(X.columns==area_type)[0][0]\n",
    "         \n",
    "    if availability!='Not Ready':        \n",
    "        avail_index = np.where(X.columns==availability)[0][0]\n",
    "            \n",
    "    x = np.zeros(len(X.columns))\n",
    "    x[0] = bath\n",
    "    x[1] = balcony\n",
    "    x[2] = bhk\n",
    "    x[3] = sqft\n",
    "    \n",
    "    if loc_index >= 0:\n",
    "        x[loc_index] = 1\n",
    "    if area_index >= 0:\n",
    "        x[area_index] = 1\n",
    "    if avail_index >= 0:\n",
    "        x[avail_index] = 1\n",
    "        \n",
    "    return model.predict([x])[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Prediction 1\n",
    "# Input in the form : Location, BHK, Bath, Balcony, Sqft, area_type, availability.\n",
    "prediction('1st Block Jayanagar', 2, 2, 2, 1000, 'Built-up  Area', 'Ready To Move')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Prediction 2\n",
    "# Input in the form : Location, BHK, Bath, Balcony, Sqft, area_type, availability.\n",
    "prediction('1st Phase JP Nagar', 2, 2, 2, 1000, 'Super built-up  Area', 'Ready To Move')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Prediction 3\n",
    "# Input in the form : Location, BHK, Bath, Balcony, Sqft, area_type, availability.\n",
    "prediction('Whitefield', 2, 2, 2, 1000, 'Plot  Area', 'Ready To Move')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "prediction('Whitefield', 2, 2, 2, 1000, 'Built-up  Area', 'Ready To Move')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
